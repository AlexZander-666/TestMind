/**
 * APIè¿æ¥æµ‹è¯•
 * å¿«é€ŸéªŒè¯APIé…ç½®æ˜¯å¦æ­£ç¡®
 */

import { LLMService } from '../packages/core/src/llm/LLMService';

async function testAPIConnection() {
  console.log('\nğŸ”§ æµ‹è¯•APIè¿æ¥...\n');
  console.log('é…ç½®ä¿¡æ¯:');
  console.log(`  API Base: ${process.env.OPENAI_API_BASE || 'default'}`);
  console.log(`  Model: ${process.env.OPENAI_MODEL || 'default'}`);
  console.log(`  API Key: ***${process.env.OPENAI_API_KEY?.substring(process.env.OPENAI_API_KEY.length - 8) || 'not set'}\n`);

  try {
    const llmService = new LLMService();

    console.log('ğŸ“¤ å‘é€æµ‹è¯•è¯·æ±‚...');
    const startTime = Date.now();

    const response = await llmService.generate({
      provider: 'openai',
      model: process.env.OPENAI_MODEL || 'gpt-4-turbo-preview',
      prompt: 'Say "Hello TestMind!" in exactly 3 words.',
      temperature: 0.1,
      maxTokens: 10000
    });

    const duration = Date.now() - startTime;

    console.log('\nâœ… APIè¿æ¥æˆåŠŸ!\n');
    console.log('å“åº”ä¿¡æ¯:');
    console.log(`  å†…å®¹: "${response.content}"`);
    console.log(`  è€—æ—¶: ${duration}ms`);
    console.log(`  Tokenä½¿ç”¨: ${response.usage?.totalTokens || 'N/A'}`);

    return true;

  } catch (error) {
    console.error('\nâŒ APIè¿æ¥å¤±è´¥:\n');
    console.error(error instanceof Error ? error.message : String(error));
    
    if (error instanceof Error && error.stack) {
      console.error('\nè°ƒè¯•ä¿¡æ¯:');
      console.error(error.stack);
    }

    return false;
  }
}

// è¿è¡Œæµ‹è¯•
testAPIConnection().then(success => {
  if (success) {
    console.log('\nğŸ‰ APIé…ç½®æ­£ç¡®ï¼Œå¯ä»¥å¼€å§‹ShannonéªŒè¯ï¼\n');
    process.exit(0);
  } else {
    console.log('\nâš ï¸  è¯·æ£€æŸ¥APIé…ç½®åé‡è¯•\n');
    process.exit(1);
  }
});

