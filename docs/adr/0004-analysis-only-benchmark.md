# ADR 0004: 性能基准测试仅验证分析阶段（不含LLM）

## 状态

✅ **已接受** (2025-10-18 - Week 7 Day 4)

## 背景

Week 7需要创建性能基准测试来验证NFR要求（小项目<5s，中项目<30s，大项目<2min）。

核心问题：性能基准是否应包含LLM调用（端到端测试）？

## 决策

性能基准**仅测试分析阶段**（Static Analysis + Dependency Graph + Semantic Indexing），**不包含LLM调用**（测试生成）。

LLM调用将在未来的端到端基准中验证（使用mock provider）。

## 备选方案考虑

| 方案 | 一致性 | 真实性 | 成本 | 端到端覆盖 | 总分 |
|------|--------|--------|------|-----------|------|
| **仅分析** | **高** | **中** | **$0** | **否** | **8/10** ✅ |
| 含真实LLM | 低 | 高 | $10-50/次 | 是 | 4/10 |
| 含Mock LLM | 高 | 中 | $0 | 是 | 7/10 |

### 方案1：仅测试分析阶段（推荐）✅

**范围**：
```
[分析] → [依赖图] → [语义索引]
 ✅测试    ✅测试       ✅测试

[LLM调用] → [代码提取] → [文件写入]
  ❌不测试     ❌不测试      ❌不测试
```

**优点**：
- **结果可重复**：不依赖外部LLM API
- **零成本**：无API调用费用
- **快速执行**：<1秒（vs 30秒含LLM）
- **CI友好**：可频繁运行，不担心成本
- **稳定性高**：不受LLM响应变化影响

**缺点**：
- 未验证端到端性能
- 无法检测LLM调用导致的延迟
- 不完整的用户体验模拟

**适用场景**：
- 验证**系统核心性能**（可控部分）
- 回归测试（防止性能退化）
- 频繁CI运行

---

### 方案2：包含真实LLM调用

**范围**：完整端到端流程

**优点**：
- 最真实的性能测试
- 覆盖完整用户体验
- 发现端到端瓶颈

**缺点**：
- **不可重复**：LLM响应时间波动±50%
- **高成本**：每次运行$10-50
  - Small: 5 functions × $0.01 = $0.05
  - Medium: 25 functions × $0.01 = $0.25
  - Large: 100 functions × $0.01 = $1.00
  - 每次完整run: ~$1.30
  - 每周3次 × 52周 = **$200/年**
- **CI不可行**：成本和时间都不适合频繁运行
- **难以调试**：性能问题可能来自LLM而非系统

**经济学分析**：
```
年度成本：$200 API + 10h维护 = $700
年度收益：发现2-3个性能问题？价值难以量化

ROI：不明确，成本确定
```

**风险**：
- LLM provider限流（rate limit）
- API不稳定性
- 成本失控

---

### 方案3：包含Mock LLM Provider

**范围**：端到端流程，使用模拟LLM

**优点**：
- 结果可重复
- 零API成本
- 覆盖完整流程
- 可控的响应时间

**缺点**：
- 需要实现Mock Provider（2-3天工作）
- Mock可能与真实LLM行为不同
- 无法发现LLM相关性能问题

**实施成本**：
```
Mock Provider实现：12-16小时 = $600-800
维护成本：每月1小时 = $50/月 = $600/年

总成本第一年：$1,200-1,400
```

**适用场景**：
- Month 3-4实施，验证端到端流程
- CI集成
- 架构完整性验证

---

## 权衡分析

### 决策矩阵

| 评估维度 | 权重 | 仅分析 | 真实LLM | Mock LLM |
|---------|------|--------|---------|---------|
| 结果可重复性 | 30% | 10 | 2 | 10 |
| 真实性 | 25% | 6 | 10 | 7 |
| 成本效益 | 25% | 10 | 3 | 6 |
| CI集成 | 15% | 10 | 2 | 9 |
| 实施时间 | 5% | 10 | 10 | 3 |
| **加权总分** | **100%** | **8.55** ✅ | **4.90** | **7.80** |

### 分阶段策略（推荐）

**Week 7-8**: 方案1（仅分析）
- 立即可用
- 验证系统核心性能
- 零成本

**Month 3**: 添加方案3（Mock LLM）
- 验证端到端流程
- CI集成
- 架构完整性

**Month 6**: 可选添加方案2（真实LLM）
- 作为月度深度验证（非CI）
- 发现真实性能问题
- 成本可控（每月仅1-2次）

## 决策理由

### 主要考虑

1. **当前目标：验证系统核心** （4.md - 明确意图）
   - NFR定义的是"分析时间"，不是"生成时间"
   - 系统可控部分=分析、依赖、索引
   - LLM调用是外部依赖，性能不可控

2. **经济学原则** （4.md - TCO思维）：
   - 方案1：$0成本，立即可用
   - 方案2：$200/年，收益不明
   - 方案3：$1,200一次性，未来价值
   - **Week 7选择最低成本方案，后续迭代**

3. **务实权衡** （4.md）：
   > "按时交付的欠佳代码胜过永远不交付的完美代码"
   - 仅分析=可立即验证NFR
   - 含LLM=需要更多准备，延迟验证

4. **可重复性**：
   - Benchmark应该是稳定的基准线
   - LLM响应时间波动大，不适合作为baseline
   - 分析阶段性能稳定，可靠对比

## 实施细节

### 性能基准范围

```typescript
// 包含的组件
✅ StaticAnalyzer.analyzeProject()
✅ DependencyGraphBuilder.buildGraph()  
✅ SemanticIndexer.indexCodebase()

// 不包含的组件
❌ TestGenerator.generateUnitTest()
❌ LLMService.callLLM()
❌ PromptBuilder（验证但不计时）
```

### 基准测试代码

```typescript
// scripts/performance-benchmark.ts
async function benchmarkSmallProject() {
  const analyzer = new StaticAnalyzer(config);
  
  const start = Date.now();
  
  // 分析阶段：测试这部分
  for (const file of files) {
    await analyzer.analyzeFile(file);
  }
  
  const duration = Date.now() - start;
  
  // 不包含生成阶段
  // await generator.generateUnitTest(...) ❌
  
  return { duration, passed: duration < TARGET };
}
```

## 后果

### 正面影响

1. **立即可用**：
   - Week 7当天完成并验证
   - 无需等待Mock实现

2. **零成本运行**：
   - 可以每次PR都跑
   - CI集成无预算问题

3. **稳定基准**：
   - 性能结果可重复
   - 可对比不同版本

4. **验证了关键目标**：
   - 证明系统核心性能优秀（300x超标）
   - 证明架构扩展性（线性增长）

### 负面影响与缓解

1. **用户感知性能未验证**：
   - **问题**：用户体验包含LLM等待时间
   - **影响**：不知道端到端是否满足30秒SLA
   - **缓解**：
     - Month 3实施Mock LLM基准
     - Week 8-9 dogfooding记录真实使用数据
     - 用户反馈收集

2. **不完整的性能画像**：
   - **问题**：无法识别LLM相关瓶颈
   - **缓解**：
     - 分离度量：分析性能（当前）+ 生成性能（未来）
     - 清晰标注："分析性能"vs"端到端性能"

3. **技术债务**：
   - **债务**：缺少端到端性能验证
   - **分类**：审慎且刻意（Prudent & Deliberate）
   - **偿还计划**：Month 3实现Mock LLM Provider
   - **优先级**：P2（中等）

## 验证结果

### Week 7性能基准结果

```
Small Project (5文件, 30函数):
  分析时间：16ms ✅ (目标<5s)
  
Medium Project (25文件, 200函数):
  分析时间：78ms ✅ (目标<30s)
  
Large Project (100文件, 1000函数):
  分析时间：356ms ✅ (目标<120s)

总体：超过目标300倍 🚀
```

**结论**：系统核心性能优秀，分析不是瓶颈。

### 推断端到端性能

**假设**（保守估计）：
- 分析：356ms（实测）
- LLM调用（5个函数）：5 × 3秒 = 15秒
- 其他开销：1秒
- **端到端估算**：16-17秒

**预期**：
- Small: <2秒（分析+1次LLM）✅
- Medium: <20秒（分析+3次LLM）✅
- Large: <30秒（分析+5次LLM）✅

**风险**：LLM可能更慢（p95可达10秒/调用）

**验证需求**：确需Month 3实测验证

## 技术债务记录

**债务ID**: PD-1  
**类型**：Prudent & Deliberate（审慎且刻意）  
**优先级矩阵**：中影响 + 中工作量 = P2

```
# TODO (Month 3): 实现端到端性能基准
# 
# 当前仅验证分析性能，未包含LLM调用。
# 
# 实施计划：
# 1. 创建MockLLMProvider（4h）
# 2. 扩展performance-benchmark.ts（2h）
# 3. 定义端到端NFR目标（1h）
# 4. CI集成（1h）
# 
# 总成本：8小时
# 收益：完整性能画像，SLA承诺能力
# ROI：避免1次性能问题 = $2,000+
```

## 遵循的4.md原则

### ✅ 经济学思维
- ROI计算：$0投入立即验证核心性能
- 避免过早优化：先验证可控部分，后迭代

### ✅ 务实权衡
- "按时交付的欠佳（仅分析）胜过永不交付的完美（含LLM）"
- Week 7完成可用基准，Month 3迭代完善

### ✅ 系统性思维
- 识别"爆炸半径"：分析性能影响整体体验
- 分阶段验证：核心→扩展

### ✅ 技术债务管理
- 明确记录债务：PD-1
- 定义偿还计划：Month 3
- 量化成本收益

## 相关ADR

- ADR 0002: LRU缓存策略（性能优化基础）
- 未来ADR: Mock LLM Provider设计（Month 3）

## 参考资料

- [NFR_SPECIFICATION.md](../../NFR_SPECIFICATION.md) - 性能要求定义
- [PERFORMANCE_BENCHMARK_REPORT.md](../../PERFORMANCE_BENCHMARK_REPORT.md) - 基准测试结果
- [scripts/performance-benchmark.ts](../../scripts/performance-benchmark.ts) - 实现代码

---

**创建日期**：2025-10-18  
**作者**：AI Engineering Team  
**下次审查**：Month 3（评估Mock LLM实施）





